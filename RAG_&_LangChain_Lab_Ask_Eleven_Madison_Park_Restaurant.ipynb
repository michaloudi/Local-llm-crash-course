{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaloudi/Local-llm-crash-course/blob/main/RAG_%26_LangChain_Lab_Ask_Eleven_Madison_Park_Restaurant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c81334e-f006-4469-be77-084c4e8228a4",
      "metadata": {
        "id": "2c81334e-f006-4469-be77-084c4e8228a4"
      },
      "source": [
        "# TASK 1: PROJECT OVERVIEW & KEY LEARNING OBJECTIVES"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8e6b477-febd-4481-bb9f-804da754b280",
      "metadata": {
        "id": "f8e6b477-febd-4481-bb9f-804da754b280"
      },
      "source": [
        "![image.png](attachment:01e041fe-619d-44e6-8903-d6f03244e983.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0563aa65-eabc-44ef-9eb4-73a7e7eb1161",
      "metadata": {
        "id": "0563aa65-eabc-44ef-9eb4-73a7e7eb1161"
      },
      "source": [
        "![image.png](attachment:b5417376-7793-437b-973e-a43a66a68c2b.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59d1e68e-da80-408a-b98b-f9fe12fdaea3",
      "metadata": {
        "id": "59d1e68e-da80-408a-b98b-f9fe12fdaea3"
      },
      "source": [
        "![image.png](attachment:ed082c6d-f693-4c3d-9a06-ca02fadbed8f.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc45f169-56f8-4190-ae53-756a375bb142",
      "metadata": {
        "id": "cc45f169-56f8-4190-ae53-756a375bb142"
      },
      "source": [
        "# TASK 2: UNDERSTAND RETRIEVAL AUGMENTED GENERATION (RAG)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a043c38-2d82-4d94-90fa-6bd83e467dca",
      "metadata": {
        "id": "2a043c38-2d82-4d94-90fa-6bd83e467dca"
      },
      "source": [
        "![image.png](attachment:0c99d96c-6dc2-4b7b-8086-4328ca32790e.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09edcf96-c35e-4134-96e7-ab626fccf9df",
      "metadata": {
        "id": "09edcf96-c35e-4134-96e7-ab626fccf9df"
      },
      "source": [
        "![image.png](attachment:f8f3f9eb-890c-4993-9a8b-0d5dbf076b07.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffbf7f5d-c572-4d9f-9283-4d8af989bb92",
      "metadata": {
        "id": "ffbf7f5d-c572-4d9f-9283-4d8af989bb92"
      },
      "source": [
        "![image.png](attachment:8ce7c48b-6bb9-4aaf-9dfb-9639ee653c2c.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a0206c9-666f-444d-a5c9-22e15e7911fa",
      "metadata": {
        "id": "4a0206c9-666f-444d-a5c9-22e15e7911fa"
      },
      "source": [
        "![image.png](attachment:e2de25cc-5cbf-453b-b43b-4725ce43f6b5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdc93989-f8fc-4031-8c31-5d287388a6ee",
      "metadata": {
        "id": "bdc93989-f8fc-4031-8c31-5d287388a6ee"
      },
      "source": [
        "# TASK 3: LANGCHAIN 101"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dd9ffb3-9663-4fce-a5f0-15a4d243e6ce",
      "metadata": {
        "id": "7dd9ffb3-9663-4fce-a5f0-15a4d243e6ce"
      },
      "source": [
        "![image.png](attachment:15015fd4-74e5-448c-93eb-223ecc2549d2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fc346c7-f36c-4584-891f-6d9bc425b85a",
      "metadata": {
        "id": "6fc346c7-f36c-4584-891f-6d9bc425b85a"
      },
      "source": [
        "![image.png](attachment:5416184c-f374-4632-8447-519a47b5094e.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92d1cf1c-3357-4120-af31-8850f7ec03c6",
      "metadata": {
        "id": "92d1cf1c-3357-4120-af31-8850f7ec03c6"
      },
      "source": [
        "# TASK 4. SETUP, GATHER RAG TOOLS, & LOAD THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "48e11d12-8254-48db-885c-4d7809741a73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48e11d12-8254-48db-885c-4d7809741a73",
        "outputId": "be689850-e9d5-4edf-9592-22b7b6904310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing necessary libraries...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.7/87.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.4/462.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.23.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.23.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLibraries installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# We start by installing the libraries we need and setting up our OpenAI API key\n",
        "# This cell installs the necessary libraries. Please run it once\n",
        "\n",
        "# VERY IMPORTANT: Microsoft Visual C++ 14.0 or greater is required before running this cell\n",
        "# https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
        "\n",
        "# The '-q' flag makes the installation less verbose\n",
        "print(\"Installing necessary libraries...\")\n",
        "!pip install -q langchain langchain-openai openai chromadb gradio python-dotenv tiktoken langchain-community\n",
        "print(\"Libraries installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4f1e7134-bbd5-41f9-b13b-50c518f41bc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f1e7134-bbd5-41f9-b13b-50c518f41bc6",
        "outputId": "18b2ec94-cf3c-4a02-8542-cbe4535fdf3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.13.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "OpenAI client successfully configured.\n",
            "sk-proj-RG3jQWl\n"
          ]
        }
      ],
      "source": [
        "# Let's install and import OpenAI Package\n",
        "!pip install --upgrade openai\n",
        "from openai import OpenAI\n",
        "\n",
        "# Let's import os, which stands for \"Operating System\"\n",
        "import os\n",
        "\n",
        "# This will be used to load the API key from the .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Get the OpenAI API keys from environment variables\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Let's configure the OpenAI Client using our key\n",
        "openai_client = OpenAI(api_key=openai_api_key)\n",
        "print(\"OpenAI client successfully configured.\")\n",
        "\n",
        "# Let's view the first few characters in the key\n",
        "print(openai_api_key[:15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qFQBKjlbyCpP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFQBKjlbyCpP",
        "outputId": "87c0e876-c071-4384-ed68-41dec7c40f69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ac04d1c4-615c-49ac-a5fc-d3ea18144fba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "id": "ac04d1c4-615c-49ac-a5fc-d3ea18144fba",
        "outputId": "b4108cd9-5a3a-4c75-aba5-26fc46d16780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.9)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.2.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.9)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.9->langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.9->langchain) (0.6.9)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.9->langchain) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.9->langchain) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.9->langchain) (9.1.4)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.9->langchain) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.9->langchain) (0.14.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (0.3.4)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.9->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain) (1.12.2)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.9->langchain) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.9->langchain) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.9->langchain) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.7->langchain) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.9->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.9->langchain) (2.6.3)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.chains'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2512433771.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_text_splitters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecursiveCharacterTextSplitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_loaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchains\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRetrievalQAWithSourcesChain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.chains'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Ensure langchain is up-to-date and correctly installed before importing\n",
        "!pip install --upgrade --force-reinstall langchain\n",
        "\n",
        "# Let's import Langchain components\n",
        "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.chains import RetrievalQAWithSourcesChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0904e43-185e-43d0-a56f-dc1b1e27bbcc",
      "metadata": {
        "id": "e0904e43-185e-43d0-a56f-dc1b1e27bbcc",
        "outputId": "e8dfc34d-034d-44e1-8aa2-0cfa81f5bc1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data file path set to: eleven_madison_park_data.txt\n"
          ]
        }
      ],
      "source": [
        "# Define the path to your data file\n",
        "# Ensure 'eleven_madison_park_data.txt' is in the same folder as this notebook\n",
        "DATA_FILE_PATH = \"eleven_madison_park_data.txt\"\n",
        "print(f\"Data file path set to: {DATA_FILE_PATH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ec5be4e-22f4-429b-9e61-ed34f41bf080",
      "metadata": {
        "id": "7ec5be4e-22f4-429b-9e61-ed34f41bf080",
        "outputId": "dfadaf75-ec26-4439-f311-e618083f88ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to load data from: eleven_madison_park_data.txt\n",
            "Successfully loaded 1 document(s).\n"
          ]
        }
      ],
      "source": [
        "# Let's load Eleven Madison Park Restaurant data, which has been scraped from their website\n",
        "# The data is saved in \"eleven_madison_park_data.txt\", Langchain's TextLoader makes this easy to read\n",
        "print(f\"Attempting to load data from: {DATA_FILE_PATH}\")\n",
        "\n",
        "# Initialize the TextLoader with the file path and specify UTF-8 encoding\n",
        "# Encoding helps handle various characters correctly\n",
        "loader = TextLoader(DATA_FILE_PATH, encoding = \"utf-8\")\n",
        "\n",
        "# Load the document(s) using TextLoader from LangChain, which loads the entire file as one Document object\n",
        "raw_documents = loader.load()\n",
        "print(f\"Successfully loaded {len(raw_documents)} document(s).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26677d00-49f5-40d2-b93e-ccaad0956b0d",
      "metadata": {
        "id": "26677d00-49f5-40d2-b93e-ccaad0956b0d",
        "outputId": "760520c3-0a21-4a88-8b8c-449e43521ef9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Source: https://www.elevenmadisonpark.com/\n",
            "Title: Eleven Madison Park\n",
            "Content:\n",
            "Book on Resy\n",
            "---END OF SOURCE---\n",
            "\n",
            "Source: https://www.elevenmadisonpark.com/careers\n",
            "Title: Careers — Eleven Madison Park\n",
            "Content:\n",
            "Join Our Team Eleven Madison Park ▾ All Businesses Eleven Madison Park Clemente Bar Daniel Humm Hospitality Filter Categories Culinary Pastry Wine & Beverage Dining Room Office & Admin Other Job Types Full Time Part Time Compensation Salary Hourly Apply filters OPEN OPPORTUNITIES Staff Acco...\n"
          ]
        }
      ],
      "source": [
        "# Let's display a few characters of the loaded content to perform a sanity check!\n",
        "print(raw_documents[0].page_content[:500] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69304eee-5669-4145-b9c3-7974350c4ae6",
      "metadata": {
        "id": "69304eee-5669-4145-b9c3-7974350c4ae6"
      },
      "source": [
        "**PRACTICE OPPORTUNITY:**\n",
        "- **Display the last 750 characters in the loaded document**\n",
        "- **Perform a sanity check by comparing the printed characters to `eleven_madison_park_data.txt` file**\n",
        "- **Print the email and the phone number of the restaurant**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "110bea7b-a6da-4282-9432-5c77a34056a8",
      "metadata": {
        "id": "110bea7b-a6da-4282-9432-5c77a34056a8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4acce09b-3cd1-4a1c-b1fe-84f41184b4e6",
      "metadata": {
        "id": "4acce09b-3cd1-4a1c-b1fe-84f41184b4e6"
      },
      "source": [
        "# TASK 5. SPLITTING DOCUMENTS (CHUNKING) WITH LANGCHAIN TEXT SPLITTER"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9daa01d-f6ed-4e31-a32e-ce4a3b98b060",
      "metadata": {
        "id": "b9daa01d-f6ed-4e31-a32e-ce4a3b98b060"
      },
      "source": [
        "Large documents are hard for AI models to process efficiently and make it difficult to find specific answers. We need to split the loaded document into smaller, manageable \"chunks\". We'll use Langchain's `RecursiveCharacterTextSplitter`.\n",
        "\n",
        "*   **Why chunk?** Smaller pieces are easier to embed, store, and retrieve accurately.\n",
        "*   **`chunk_size`**: Max characters per chunk.\n",
        "*   **`chunk_overlap`**: Characters shared between consecutive chunks (helps maintain context)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2f7e9ca-df96-45f5-aabd-c0ee5e6d6453",
      "metadata": {
        "id": "f2f7e9ca-df96-45f5-aabd-c0ee5e6d6453",
        "outputId": "aee85177-63e1-4874-9130-06d59175f09f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Splitting the loaded document into smaller chunks...\n",
            "Document split into 38 chunks.\n"
          ]
        }
      ],
      "source": [
        "# Let's split the document into chunks\n",
        "print(\"\\nSplitting the loaded document into smaller chunks...\")\n",
        "\n",
        "# Let's initialize the splitter, which tries to split the document on common separators like paragraphs (\\n\\n),\n",
        "# sentences (.), and spaces (' ').\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000,  # Aim for chunks of about 1000 characters\n",
        "                                               chunk_overlap = 150,)  # Each chunk overlaps with the previous by 150 characters\n",
        "\n",
        "# Split the raw document(s) into smaller Document objects (chunks)\n",
        "documents = text_splitter.split_documents(raw_documents)\n",
        "\n",
        "# Check if splitting produced any documents\n",
        "if not documents:\n",
        "    raise ValueError(\"Error: Splitting resulted in zero documents. Check the input file and splitter settings.\")\n",
        "print(f\"Document split into {len(documents)} chunks.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bc5a09d-13ba-41b7-aa8f-31220d7873bd",
      "metadata": {
        "id": "0bc5a09d-13ba-41b7-aa8f-31220d7873bd",
        "outputId": "3ee52669-c786-4c62-a13d-a43637a1a86f",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Source: https://www.elevenmadisonpark.com/\\nTitle: Eleven Madison Park\\nContent:\\nBook on Resy\\n---END OF SOURCE---'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Source: https://www.elevenmadisonpark.com/careers\\nTitle: Careers — Eleven Madison Park\\nContent:'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content=\"Join Our Team Eleven Madison Park ▾ All Businesses Eleven Madison Park Clemente Bar Daniel Humm Hospitality Filter Categories Culinary Pastry Wine & Beverage Dining Room Office & Admin Other Job Types Full Time Part Time Compensation Salary Hourly Apply filters OPEN OPPORTUNITIES Staff Accountant - Part Time Eleven Madison Park Part Time • Hourly ($20 - $25) Host/Reservationist Eleven Madison Park Full Time • Hourly ($24) Sous Chef Eleven Madison Park Full Time • Salary ($72K - $75K) Pastry Cook Eleven Madison Park Full Time • Hourly ($18 - $20) Kitchen Server Eleven Madison Park Full Time • Hourly ($16) plus tips Dining Room Manager Eleven Madison Park Full Time • Salary ($72K - $75K) Porter Manager Eleven Madison Park Full Time • Salary ($70K - $75K) Senior Sous Chef Eleven Madison Park Full Time • Salary ($85K - $95K) Maitre D Eleven Madison Park Full Time • Hourly ($16) plus tips Even if you don't see the opportunity you're looking for, we would still love to hear from you. There\"),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content=\"Madison Park Full Time • Hourly ($16) plus tips Even if you don't see the opportunity you're looking for, we would still love to hear from you. There may be a place for you on our team as we grow. × Where Do You Want To Work? Eleven Madison Park Clemente Bar Daniel Humm Hospitality I Want to Work Here\"),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='---END OF SOURCE---'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Source: https://www.elevenmadisonpark.com/giftcards\\nTitle: Gift Cards — Eleven Madison Park\\nContent:\\nGift Cards Purchase Gift Cards Here Please note that all gift card sales are final and nonrefundable.\\n---END OF SOURCE---'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Source: https://www.elevenmadisonpark.com/press-and-accolades\\nTitle: Press and Accolades — Eleven Madison Park\\nContent:\\nAccolades World’s 50 Best Best of the Best The New York Times Four Stars Michelin Guide Three Stars Wine Spectator Grand Award The World of Fine Wine Best Overall Wine List James Beard Foundation Outstanding Chef, Outstanding Service, Outstanding Pastry Chef, Outstanding Restaurant, Best Chef: NYC, Outstanding Wine Service, Rising Star Chef Recent Press Time: “Is Cooking for the 1% for a Reason” Washington Post: “The Joy of Plant-Based Eating” Interview: “Daniel Humm Is Begging You to Eat More Plants” Financial Times: \"Epicurean escapes: Alain Ducasse and Daniel Humm’s transatlantic adventure\" The Strategist: “What Chef Daniel Humm Can’t Live Without”\\n---END OF SOURCE---'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Source: https://www.elevenmadisonpark.com/accessibility-statement\\nTitle: Accessibility Statement — Eleven Madison Park\\nContent:\\nAccessibility Statement Eleven Madison Park is committed to providing digital accessibility for everyone. Our ongoing accessibility effort works towards conforming to the Web Content Accessibility Guidelines (WCAG) version 2.1, level AA criteria. These guidelines not only help make web content accessible to users with sensory, cognitive and mobility disabilities, but ultimately to all users, regardless of ability. Our ongoing accessibility efforts work toward making ElevenMadisonPark.com as accessible as possible. Eleven Madison Park welcomes comments on how to improve the site’s accessibility for users with disabilities. Please email: info@elevenmadisonpark.com .\\n---END OF SOURCE---\\n\\nSource: https://www.elevenmadisonpark.com/cart\\nTitle: Eleven Madison Park\\nContent:\\nShopping Cart You have nothing in your shopping cart. Continue Shopping\\n---END OF SOURCE---'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Source: https://www.elevenmadisonpark.com/faq\\nTitle: FAQs — Eleven Madison Park\\nContent:'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='FAQs We are located at 11 Madison Avenue, on the northeast corner of East 24th and Madison Avenue, directly across the street from Madison Square Park. We offer three menus, all 100% plant-based: Full Tasting Menu : An eight- to nine-course experience priced at $365 per guest. This menu typically lasts about two to three hours and features a mix of plated and communal dishes. 5-Course Menu : Priced at $285 per guest, this menu highlights selections from the Full Tasting Menu and lasts approximately two hours. Bar Tasting Menu : Available in our lounge for $225 per guest, this menu includes four to five courses and is designed to last around two hours. Note : These durations are estimates based on tables of two. Larger parties may require additional time. We open up reservations on the first of every month for the following month–for example, on October 1st, all of November will be made available. If you find that the reservation you were hoping for is booked, we do hold a waitlist on'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='on October 1st, all of November will be made available. If you find that the reservation you were hoping for is booked, we do hold a waitlist on Resy and encourage you to add your name to it, and if something becomes available, we will be in touch. All sales are final and non-refundable. We do not offer cancellation or rescheduling options at this time. Eleven Madison Park does not include gratuity for the dining experience. Guests are welcome to leave a desired gratuity at the conclusion of their experience at their discretion. For any questions on our gratuity policies, please contact our guest relations team at info@elevenmadisonpark.com . Not a problem! We will be verifying all food allergies, aversions, and dietary restrictions prior to you joining us, but also at the table when you arrive for your meal. Yes. We offer wine pairings, starting at $125 per guest, as well as a full wine list that our wine team can help you select from and may also be viewed on our website. You are'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='starting at $125 per guest, as well as a full wine list that our wine team can help you select from and may also be viewed on our website. You are also welcome to bring your own special bottle of wine for your meal for a $75 per 750ml bottle corkage (4 bottle maximum) fee. We do not have a dress code. Many of our guests dress up for the occasion but wear whatever will make you most comfortable. You can reach our reservations team at any time at info@elevenmadisonpark.com . We can accommodate up to seven guests at a table in the main dining room. If you are interested in booking a table for a group larger than this, please contact our Private Dining and Special Events team at events@elevenmadisonpark.com . Yes, you can. Reservations for our Bar Tasting menu are available at our lounge tables and are $225 per guest; you may also order a number of items a la carte. Seats at the bar counter are on a first-come, first-serve basis. You may order our Bar Tasting menu in addition to'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='a number of items a la carte. Seats at the bar counter are on a first-come, first-serve basis. You may order our Bar Tasting menu in addition to cocktails, light snacks, and our a la carte menu. Unfortunately, Resy does not have the capability to accept gift cards as a form of payment at this time. Please secure your reservation using an alternate payment method, and our accounting team will be happy to help redeem your Eleven Madison Park gift card and credit the form of payment you used to make the booking. Contact Marcia Regen ( mregen@hummhospitality.com ) for help. You can always also bring Eleven Madison Park gift cards into the restaurant when you dine to be used toward any beverage purchased on site. To purchase a Braille gift card, please contact Marcia Regen ( mregen@hummhospitality.com ).'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='---END OF SOURCE---'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Source: https://www.elevenmadisonpark.com/ourrestaurant\\nTitle: About — Eleven Madison Park\\nContent:'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Welcome to Eleven Madison Park Eleven Madison Park is a fine dining restaurant in the heart of New York City. Overlooking Madison Square Park–one of Manhattan’s most beautiful green spaces–we sit at the base of a historic Art Deco building on the corner of East 24th Street and Madison Avenue. Since opening in 1998, we underwent a full-scale renovation and redesign in the summer of 2017. Chef Daniel Humm has owned the restaurant since 2011, during which time we have evolved considerably in both cuisine and experience. In 2021, we transitioned to a fully plant-based menu, using no animal products. That same year, we partnered with Magic Farms , which grows produce exclusively for our seasonal menus. Guests can enjoy a full tasting menu, a five-course menu, or a bar menu. The bar also offers à la carte snacks, as well as wine and cocktails. Reservations are available via Resy , and bar seating is open for both walk-ins and reservations. Hours: Monday to Wednesday: 5:30 pm to 10 pm'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Reservations are available via Resy , and bar seating is open for both walk-ins and reservations. Hours: Monday to Wednesday: 5:30 pm to 10 pm Thursday to Friday: 5 pm to 11 pm Saturday: 12 pm to 2 pm, 5 pm to 11 pm Sunday: 12 pm to 2 pm, 5 pm to 11 pm View Wine List View Cocktail List Due to the hyper-seasonal nature of our menu, all courses are subject to change. Therefore, we do not share our food menus online. Book on Resy'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='---END OF SOURCE---'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Source: https://www.elevenmadisonpark.com/magic-farms\\nTitle: Magic Farms — Eleven Madison Park\\nContent:'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='About Magic Farms As part of our transition to a plant-based menu, it was important for us to build a deeper connection to the ingredients we use in our kitchen. In 2021, we partnered with Chef Daniel Humm’s friend, Maciek Kobielski, to create Magic Farms on his family’s land in Hoosick Falls, New York. What began as a passion project for Maciek has become a full-time career. The farm now spans four acres of fields and seven high tunnels, growing produce exclusively for our seasonal menus. At the restaurant, this partnership has profoundly influenced our craft, fostering an ongoing dialogue between chef and farmer that shapes every menu. Our team collaborates with Maciek to plan menus around his harvest cycles and crop rotations, mapping out seasons in advance. Maciek grows each vegetable to our specifications using pesticide-free, regenerative techniques, with harvests peaking in the warmer months. This ensures access to the freshest, most flavorful produce year-round and allows each'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='techniques, with harvests peaking in the warmer months. This ensures access to the freshest, most flavorful produce year-round and allows each menu to reflect the best of the Northeast’s seasons. Book on Resy Maciek and Chef Humm Cherry Tomato Sunset over Magic Farms Delivery to the Restaurant Squash Blossoms Chefs Mattia and Josh visiting the farm. Badger Flame Beets Garlic Bulbs Sunflower Harvest A Tunnel in Spring Eggplants Greens Growing Radicchio Snow Day Maciek on His Tractor Radish Harvest Lettuces Growing Item 1 of 17'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='---END OF SOURCE---'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Source: https://www.elevenmadisonpark.com/team\\nTitle: Team — Eleven Madison Park\\nContent:'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Daniel Humm is a chef, author, speaker, and owner of Daniel Humm Hospitality , the New York-based hospitality group behind the highly acclaimed Eleven Madison Park, Clemente Bar , and direct-to-consumer lifestyle brand Eleven Madison Home . A native of Switzerland, Chef Humm earned his first Michelin star at the age of 24. He is consistently listed as one of the world’s best chefs, with both he and Eleven Madison Park receiving numerous accolades: four stars from The New York Times, seven James Beard Foundation Awards (including Outstanding Chef and Outstanding Restaurant in America), a number one spot on the world’s 50 Best Restaurants list, and three Michelin stars for over 12 years in a row, since 2012. At the height of the COVID-19 pandemic, Chef Humm transformed Eleven Madison Park’s Michelin-starred restaurant and its back-of-house into a commissary kitchen in partnership with Rethink Food , a not-for-profit organization co-founded by Chef Humm. He and his team prepared over'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='into a commissary kitchen in partnership with Rethink Food , a not-for-profit organization co-founded by Chef Humm. He and his team prepared over 1,000,000 meals over the course of the pandemic for frontline workers and underserved communities and distributed them to churches, shelters, and food banks. In 2021, he reopened Eleven Madison Park with a completely plant-based menu and became the first and only plant-based restaurant in Michelin Guide history to receive a three-star rating in October 2022. Gwendal Poullennec, the International Director of the Michelin Guides, has called Chef Humm and Eleven Madison Park a North Star that young chefs can fix their eyes upon as they navigate their gastronomic journey. Chef Humm uses his global platform to advocate for equitable, sustainable food systems. He wants to inspire people both within and beyond the fine-dining world and build awareness around the transformative power of food. As a leading figure in the culinary realm, he ignited a'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='and beyond the fine-dining world and build awareness around the transformative power of food. As a leading figure in the culinary realm, he ignited a conversation about challenging the definition of luxury in the food world and how it can be more purpose-driven at the United Nations Climate Change Conference in Glasgow, Scotland, in 2021. He discussed the impact of our food systems on the environment at the 2023’s Global Citizen Summit, joining activists and world leaders such as Canadian Prime Minister Justin Trudeau and French President Macron in setting a global agenda for action on the most urgent issues facing humanity and the planet. In September 2024, he was appointed UNESCO Goodwill Ambassador for Food Education by Audrey Azoulay, UNESCO’s Director-General. Chef Humm is the author of Eleven Madison Park: The Cookbook , I Love New York: Ingredients and Recipes , The NoMad Cookbook, Eleven Madison Park: The Next Chapter , and Eat More Plants . His latest book, titled Eleven'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='New York: Ingredients and Recipes , The NoMad Cookbook, Eleven Madison Park: The Next Chapter , and Eat More Plants . His latest book, titled Eleven Madison Park: The Plant-Based Chapter , was released in November 2024. Dominique Roy’s passion for cooking began at a young age, baking bread alongside his mother in his hometown of Gatineau, Canada. After attending culinary school at 17 and pastry school at 19, Dom worked for renowned chefs in Canada and France, including Georges Blanc and Jerome Ferrer. He participated in many different cooking competitions, including representing Team Canada in the Luxembourg Culinary World Cup in 2014. Dom always knew he wanted to work for one of the best restaurants in the world, and after staging at Maaemo in Oslo and Mirazur in France, he arrived in New York City from Montréal. He started with Eleven Madison Park in 2015, holding various positions, including Sous Chef and Culinary Research & Development. He also led the opening team of Davies &'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Madison Park in 2015, holding various positions, including Sous Chef and Culinary Research & Development. He also led the opening team of Davies & Brook in London in 2019. During the COVID-19 pandemic in 2020, Dom spearheaded the Eleven Madison Park and Rethink Food partnership, leading the program that provided hundreds of thousands of meals to both food-insecure residents of New York City as well as frontline workers. In 2021, he assumed the title of Chef de Cuisine, leading the reopening and building the vision for EMP’s future, and in 2023 he became a partner at Daniel Humm Hospitality. Laura Cronin grew up having a love for food at an early age, working in bakeries in her hometown of Berkeley Heights, New Jersey. After graduating culinary school at Johnson & Wales University in Rhode Island, she moved across the country to pursue a career on the baking team at the San Francisco Baking Institute under the tutelage of Michel Suas. A year later, Laura relocated to Paris and enrolled'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='on the baking team at the San Francisco Baking Institute under the tutelage of Michel Suas. A year later, Laura relocated to Paris and enrolled at the Ecole Gregoire-Ferrandi, which led to an apprenticeship with Chef Angelo Musa. In 2011, Laura moved back to the States and worked in several restaurants including Zero Zero and Perbacco, where she was named San Francisco Chronicle’s Rising Star Chef and Zagat’s 30 under 30 list. In 2017, Laura moved to New York City to join the Eleven Madison Park team as a Pastry Sous Chef leading the team through the restaurant’s reopening and working closely with Executive Pastry Chef Mark Welker, she assumed the Pastry Chef role in 2019. Originally from New Jersey, Daniel DiStefano is the Executive Culinary Director for Daniel Humm Hospitality. Danny joined the team in 2009, starting as a commis and working his way up to sous chef in 2011. He has been instrumental in launching brands such as Made Nice and Eleven Madison Home. Following the pandemic,'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='his way up to sous chef in 2011. He has been instrumental in launching brands such as Made Nice and Eleven Madison Home. Following the pandemic, Danny returned as a Managing Partner to spearhead our at-home program and strategic partnerships, and in 2024, Danny assumed the role of Executive Culinary Director. In this role, he leads culinary operations and works closely with Chef Humm and the rest of the culinary development team on menus, partnerships, events, collaborations, and new projects. Josh Harnden was born in Seattle, Washington, where he was raised with a plant-based diet, which fueled his passion for food and the culinary arts from a young age. Immersed in the restaurant industry for over two decades, he worked his way through the Seattle culinary scene—including at the renowned Canlis—before moving to New York in 2011 to help open and manage Chef Daniel Humm’s restaurant at NoMad Hotel. After helping NoMad earn its first Michelin star, Josh was asked to join the team at'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='open and manage Chef Daniel Humm’s restaurant at NoMad Hotel. After helping NoMad earn its first Michelin star, Josh was asked to join the team at Eleven Madison Park, where he has held a number of different management positions, including leading research and development. In this role, he helped to launch a range of pop-ups and openings for Daniel Humm Hospitality, as well as developing recipes for the NoMad and Eleven Madison Park cookbooks, including this one. He is now a partner and the Creative Culinary Director for Daniel Humm Hospitality. Andrew Chandler was essentially born into restaurants, spending much of his childhood watching his mother command the dining rooms of some of the best restaurants in his home state of Wisconsin. He followed in her footsteps, taking on his first jobs bussing tables and washing dishes as a teenager. After high school, he graduated from University of Wisconsin-Platteville with a bachelor’s degree in Psychology. He went on to spend several years'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='After high school, he graduated from University of Wisconsin-Platteville with a bachelor’s degree in Psychology. He went on to spend several years working with children with special needs, while simultaneously working full time in some of the best restaurants in Milwaukee, including Riversite and Braise. Eventually it became clear that his true calling was working in the dining room, and in 2012 he moved across the country to start as a Kitchen Server at Eleven Madison Park. Andrew has worked through nearly every position in the restaurant, making the transition to management in 2016. Within Make it Nice he has led the team through the pop-up EMP Summer House, the subsequent reopening of Eleven Madison Park, and the opening of Davies and Brook in London. For our General Manager, Gabriel Di Bella, an understanding of delicious food and wine runs in the family. The son of an Italian chef, he grew up helping out in his parents’ restaurant in France. As a young adult, he studied at the'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='wine runs in the family. The son of an Italian chef, he grew up helping out in his parents’ restaurant in France. As a young adult, he studied at the wine school of Tain-l’Hermitage in the heart of the Rhône Valley, before joining the wine team at Alain Ducasse in Monaco. He later spent time at Marcus at The Berkeley and the Birley Clubs in London. Gabriel came on board at Daniel Humm Hospitality as the opening Wine Director for Davies & Brook in 2019, and in 2021, he joined us at Eleven Madison Park as our Wine Director. Today, he leads the team as our General Manager. Our Wine Director, Adam Waddell, was born and raised on the West Coast, where he started violin studies at the age of four. After coming to New York in 2010 to continue studies in Classical Violin Performance, he soon developed a new-found passion for wine and hospitality. Since then, he has worked at many well-known New York City restaurants, such as Jean-Georges, Ai Fiori, and Gabriel Kreuther. Adam was the first'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Since then, he has worked at many well-known New York City restaurants, such as Jean-Georges, Ai Fiori, and Gabriel Kreuther. Adam was the first Head Sommelier at SAGA by Jamal James Kent and joined Eleven Madison Park in 2023 as Associate Wine Director. In 2025, he was named Wine Director and now leads the program with dedication and expertise. Sebastian Tollius has been perfecting his craft in the hospitality industry for almost 15 years. Before joining us at Eleven Madison Park in 2019, he worked in some of the best bars and hotels around the world, including in Switzerland, Thailand, and Spain. Bringing a range of innovative concepts and a culinary approach, Sebastian expertly led our Beverage team through our 2021 re-opening and plant-based transition, and he has transformed our cocktail program through new plant-based techniques and ingredients. He and his team now work closely with our chefs in the kitchen to create a brand-new cocktail menu each season that complements and'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='and ingredients. He and his team now work closely with our chefs in the kitchen to create a brand-new cocktail menu each season that complements and highlights ingredients from the tasting menu – constantly pushing boundaries when it comes to both technique and flavor. Mattia Rancati, Senior Sous Chef Stefano Casale , Senior Sous Chef Davide Peli, Sous Chef Luis Garcia, Sous Chef Marissa Mazzella, Sous Chef Pascal Rauwolf, Executive Pastry Sous Chef Orianna Mendez, Junior Pastry Sous Chef Pooja Harsora, Junior Sous Chef Youngbo Lee, Junior Sous Chef Alexander Mies, Purchasing Manager James Gale, Service Director Harry Basley, Dining Room Manager Eliazar Cervantes, Restaurant Operations Manager Marina Dos Santos Malta, Guest Relations Manager Caitlin McBride, Private Dining Room Manager'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='---END OF SOURCE---'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Source: https://www.elevenmadisonpark.com/events\\nTitle: Events — Eleven Madison Park\\nContent:\\nEvents & Private Dining Our restaurant offers a variety of stunning spaces to suit any event, from intimate gatherings to grand celebrations. Each space has its own unique character, seamlessly blending art, design, and exceptional hospitality. Whether you envision a seated dinner, a cocktail reception, or a corporate meeting, our thoughtfully designed venues can be tailored to your needs. For more information about hosting an event with us, please review our Private Events Deck , or contact the Private Dining and Special Events Department using the form linked below. Learn More Inquire\\n---END OF SOURCE---'),\n",
              " Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Source: https://www.elevenmadisonpark.com/contact\\nTitle: Contact — Eleven Madison Park\\nContent:\\nContact Us Visit Resy Note: We open up reservations on the first of every month for the following month - for example, on October 1st, all of November will be made available. If you find that the reservation you were hoping for is booked, we do hold a waitlist and encourage you to add your name to it, and if something does become available, we will be in touch. Please contact careers@elevenmadisonpark.com or visit Culinary Agents . To stay up to date about future Eleven Madison Park news and events, please sign up for our Newsletter . Please contact events@elevenmadisonpark.com Please contact press@elevenmadisonpark.com Thank you for thinking of Eleven Madison Park for your inquiry. At this time, all of our non-profit efforts are focused on our partnership with Rethink Food . Email: info@elevenmadisonpark.com Phone: 212.889.0905 Ext. 3\\n---END OF SOURCE---')]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's display the Python list containing document chunks\n",
        "documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3c8d6f3-f346-404b-a9a1-e6de6f29dcca",
      "metadata": {
        "id": "d3c8d6f3-f346-404b-a9a1-e6de6f29dcca",
        "outputId": "1225e8c5-34fb-48d8-d553-cc21eed642d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Example Chunk (Chunk 2) ---\n",
            "Join Our Team Eleven Madison Park ▾ All Businesses Eleven Madison Park Clemente Bar Daniel Humm Hospitality Filter Categories Culinary Pastry Wine & Beverage Dining Room Office & Admin Other Job Types Full Time Part Time Compensation Salary Hourly Apply filters OPEN OPPORTUNITIES Staff Accountant - Part Time Eleven Madison Park Part Time • Hourly ($20 - $25) Host/Reservationist Eleven Madison Park Full Time • Hourly ($24) Sous Chef Eleven Madison Park Full Time • Salary ($72K - $75K) Pastry Cook Eleven Madison Park Full Time • Hourly ($18 - $20) Kitchen Server Eleven Madison Park Full Time • Hourly ($16) plus tips Dining Room Manager Eleven Madison Park Full Time • Salary ($72K - $75K) Porter Manager Eleven Madison Park Full Time • Salary ($70K - $75K) Senior Sous Chef Eleven Madison Park Full Time • Salary ($85K - $95K) Maitre D Eleven Madison Park Full Time • Hourly ($16) plus tips Even if you don't see the opportunity you're looking for, we would still love to hear from you. There\n",
            "\n",
            "--- Metadata for Chunk 2 ---\n",
            "{'source': 'eleven_madison_park_data.txt'}\n"
          ]
        }
      ],
      "source": [
        "# Let's display an example chunk and its metadata\n",
        "print(\"\\n--- Example Chunk (Chunk 2) ---\")\n",
        "print(documents[2].page_content)\n",
        "print(\"\\n--- Metadata for Chunk 2 ---\")\n",
        "print(documents[2].metadata) # Should show {'source': 'eleven_madison_park_data.txt'}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "178349df-b4d7-4273-98ac-7aa0396b5ad2",
      "metadata": {
        "id": "178349df-b4d7-4273-98ac-7aa0396b5ad2"
      },
      "source": [
        "**PRACTICE OPPORTUNITY:**\n",
        "- **Change `chunk_size` to `500` in the `RecursiveCharacterTextSplitter` and re-run the cell. How many chunks do you get now? Is it more or less than before? Change it back to `1000`**\n",
        "- **Change `chunk_overlap` to `0` and re-run the cell. Does the number of chunks change drastically? What problem might setting overlap to 0 cause? Change it back to `150`**\n",
        "- **Print the last example chunk and its metadata and re-run the cell. What information is stored in the `metadata`? Why is the `'source'` important?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05df5a84-6f9c-4550-8c0f-4d4ff00b1c55",
      "metadata": {
        "id": "05df5a84-6f9c-4550-8c0f-4d4ff00b1c55"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6ef3184a-2d78-4952-b32e-73a0a6b25cc1",
      "metadata": {
        "id": "6ef3184a-2d78-4952-b32e-73a0a6b25cc1"
      },
      "source": [
        "# TASK 6. EMBEDDINGS AND VECTOR STORE CREATION"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252f43f2-5abd-43db-b24e-27cf8219b1d4",
      "metadata": {
        "id": "252f43f2-5abd-43db-b24e-27cf8219b1d4"
      },
      "source": [
        "![image.png](attachment:84a7928c-59d4-4390-b7ca-3692a003465a.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecb08e09-3e2e-4d3f-8563-0ee928a56251",
      "metadata": {
        "id": "ecb08e09-3e2e-4d3f-8563-0ee928a56251"
      },
      "source": [
        "![image.png](attachment:59f18738-3814-4b55-a9f5-8c954d21660a.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42795694-585f-4a02-b412-69798a743e60",
      "metadata": {
        "id": "42795694-585f-4a02-b412-69798a743e60"
      },
      "source": [
        "![image.png](attachment:abed78b5-eaba-4db8-be1f-f47021df3f68.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c13e7a6c-c290-4fa1-88b4-eb657933da65",
      "metadata": {
        "id": "c13e7a6c-c290-4fa1-88b4-eb657933da65"
      },
      "source": [
        "\n",
        "Now, we convert our text chunks into **embeddings** (numerical vectors) using OpenAI. Similar text chunks will have similar vectors. We then store these vectors in a **vector store** (ChromaDB) for fast searching.\n",
        "\n",
        "*   **Embeddings:** Text -> Numbers (Vectors) representing meaning.\n",
        "*   **Vector Store:** Database optimized for searching these vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd383e70-963a-42e9-81af-320660cf76ff",
      "metadata": {
        "id": "bd383e70-963a-42e9-81af-320660cf76ff"
      },
      "source": [
        "Tensorflow Ebeddings projector (it's fun!): https://projector.tensorflow.org/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d1466c3-f149-45b9-b488-3c69b81c9ec2",
      "metadata": {
        "id": "4d1466c3-f149-45b9-b488-3c69b81c9ec2",
        "outputId": "e441ee3a-eb34-4a6d-b943-e8252dde9ce4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing OpenAI Embeddings model...\n",
            "OpenAI Embeddings model initialized.\n",
            "\n",
            "Creating ChromaDB vector store and embedding documents...\n",
            "ChromaDB vector store created with 38 items.\n"
          ]
        }
      ],
      "source": [
        "# Let's initialize our embeddings model. Note that we will use OpenAI's embedding model\n",
        "print(\"Initializing OpenAI Embeddings model...\")\n",
        "\n",
        "# Create an instance of the OpenAI Embeddings model\n",
        "# Langchain handles using the API key we loaded earlier\n",
        "embeddings = OpenAIEmbeddings(openai_api_key = openai_api_key)\n",
        "\n",
        "print(\"OpenAI Embeddings model initialized.\")\n",
        "\n",
        "# Let's Create ChromaDB Vector Store\n",
        "print(\"\\nCreating ChromaDB vector store and embedding documents...\")\n",
        "\n",
        "# Now the chunks from 'documents' are being converted to a vector using the 'embeddings' model\n",
        "# The vectors are then stored as a vector in ChromaDB\n",
        "# You could add `persist_directory=\"./my_chroma_db\"` to save it to disk\n",
        "# You will need to specify: (1) The list of chunked Document objects and (2) The embedding model to use\n",
        "vector_store = Chroma.from_documents(documents = documents, embedding = embeddings)\n",
        "\n",
        "# Verify the number of items in the store\n",
        "vector_count = vector_store._collection.count()\n",
        "print(f\"ChromaDB vector store created with {vector_count} items.\")\n",
        "\n",
        "if vector_count == 0:\n",
        "    raise ValueError(\"Vector store creation resulted in 0 items. Check previous steps.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa8bc753-5d08-4979-a66d-14c7cb11f041",
      "metadata": {
        "id": "aa8bc753-5d08-4979-a66d-14c7cb11f041",
        "outputId": "d00a6c43-2709-4027-cd37-2cb6457b2b01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First chunk text:\n",
            " Source: https://www.elevenmadisonpark.com/\n",
            "Title: Eleven Madison Park\n",
            "Content:\n",
            "Book on Resy\n",
            "---END OF SOURCE---\n",
            "\n",
            "Embedding vector:\n",
            " [ 0.02330522 -0.01571015 -0.00706136 ... -0.02464633 -0.01022939\n",
            " -0.06158162]\n",
            "\n",
            "Full embedding has 1536 dimensions.\n"
          ]
        }
      ],
      "source": [
        "# Let's retrieve the first chunk of stored data from the vector store\n",
        "stored_data = vector_store._collection.get(include=[\"embeddings\", \"documents\"], limit = 1)\n",
        "\n",
        "# Display the results\n",
        "print(\"First chunk text:\\n\", stored_data['documents'][0])\n",
        "print(\"\\nEmbedding vector:\\n\", stored_data['embeddings'][0])\n",
        "print(f\"\\nFull embedding has {len(stored_data['embeddings'][0])} dimensions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85a6e779-1c14-4aa8-ac1c-babd4bf3274b",
      "metadata": {
        "id": "85a6e779-1c14-4aa8-ac1c-babd4bf3274b"
      },
      "source": [
        "**PRACTICE OPPORTUNITY:**\n",
        "- **Using Tensorflow Embeddings Projector, explore the nearest points to \"Italy\"**\n",
        "- **Choose 2 additional different words that you like**\n",
        "- **Tensorflow Ebeddings projector: https://projector.tensorflow.org/**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445a53e5-104c-4079-8cba-294889b1586f",
      "metadata": {
        "id": "445a53e5-104c-4079-8cba-294889b1586f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "092394dc-9260-468f-b7f1-7cad0da559db",
      "metadata": {
        "id": "092394dc-9260-468f-b7f1-7cad0da559db"
      },
      "source": [
        "# TASK 7. TESTING THE RETRIEVAL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51aeebdd-237f-4031-be1b-e5f79dc8a172",
      "metadata": {
        "id": "51aeebdd-237f-4031-be1b-e5f79dc8a172"
      },
      "source": [
        "Before building the full Q&A chain, let's test if our vector store can find relevant chunks based on a sample question. We'll use the `similarity_search` method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6aaf7c2-02a1-40c5-b14c-1e35a2bb1bb6",
      "metadata": {
        "id": "c6aaf7c2-02a1-40c5-b14c-1e35a2bb1bb6",
        "outputId": "edcc7090-4d62-4e7c-c43a-b13e20449e7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Testing Similarity Search in Vector Store ---\n",
            "Searching for documents similar to: 'What different menus are offered?'\n",
            "\n",
            "Found 2 similar documents:\n",
            "\n",
            "--- Document 1 ---\n",
            "Content Snippet: FAQs We are located at 11 Madison Avenue, on the northeast corner of East 24th and Madison Avenue, directly across the street from Madison Square Park. We offer three menus, all 100% plant-based: Full Tasting Menu : An eight- to nine-course experience priced at $365 per guest. This menu typically lasts about two to three hours and features a mix of plated and communal dishes. 5-Course Menu : Priced at $285 per guest, this menu highlights selections from the Full Tasting Menu and lasts approximately two hours. Bar Tasting Menu : Available in our lounge for $225 per guest, this menu includes four to five courses and is designed to last around two hours. Note : These durations are estimates bas...\n",
            "Source: eleven_madison_park_data.txt\n",
            "\n",
            "--- Document 2 ---\n",
            "Content Snippet: Reservations are available via Resy , and bar seating is open for both walk-ins and reservations. Hours: Monday to Wednesday: 5:30 pm to 10 pm Thursday to Friday: 5 pm to 11 pm Saturday: 12 pm to 2 pm, 5 pm to 11 pm Sunday: 12 pm to 2 pm, 5 pm to 11 pm View Wine List View Cocktail List Due to the hyper-seasonal nature of our menu, all courses are subject to change. Therefore, we do not share our food menus online. Book on Resy...\n",
            "Source: eleven_madison_park_data.txt\n"
          ]
        }
      ],
      "source": [
        "# Let's perform a similarity search in our vector store\n",
        "print(\"\\n--- Testing Similarity Search in Vector Store ---\")\n",
        "test_query = \"What different menus are offered?\"\n",
        "print(f\"Searching for documents similar to: '{test_query}'\")\n",
        "\n",
        "\n",
        "# Perform a similarity search. 'k=2' retrieves the top 2 most similar chunks\n",
        "try:\n",
        "    similar_docs = vector_store.similarity_search(test_query, k = 2)\n",
        "    print(f\"\\nFound {len(similar_docs)} similar documents:\")\n",
        "\n",
        "    # Display snippets of the retrieved documents and their sources\n",
        "    for i, doc in enumerate(similar_docs):\n",
        "        print(f\"\\n--- Document {i+1} ---\")\n",
        "        # Displaying the first 700 chars for brevity\n",
        "        content_snippet = doc.page_content[:700].strip() + \"...\"\n",
        "        source = doc.metadata.get(\"source\", \"Unknown Source\")  # Get source from metadata\n",
        "        print(f\"Content Snippet: {content_snippet}\")\n",
        "        print(f\"Source: {source}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during similarity search: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08bada62-775b-401f-affc-ad9aa79aa92a",
      "metadata": {
        "id": "08bada62-775b-401f-affc-ad9aa79aa92a"
      },
      "source": [
        "**PRACTICE OPPORTUNITY:**\n",
        "- **Change the `test_query` variable to ask one of the following questions. Re-run the cell for each question. Do the retrieved document snippets seem relevant to your question?**\n",
        "    - `\"Who is Daniel Humm?\"`\n",
        "    - `\"Is there a dress code?\"`\n",
        "    - `\"Tell me about the partnership with Magic Farms.\"`\n",
        "    - `\"How do I make a reservation?\"`\n",
        "- **Adjust the value of k to `k=1` and then to `k=5`. Re-run the cell. How does changing `k` affect the number of documents retrieved?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c434956e-539f-4f43-8d80-6fb74b4987e8",
      "metadata": {
        "id": "c434956e-539f-4f43-8d80-6fb74b4987e8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "494adb66-bec0-48ae-bcab-a4830cd7d2fa",
      "metadata": {
        "id": "494adb66-bec0-48ae-bcab-a4830cd7d2fa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1bfa7c67-b96a-41e0-89b6-1ea801c9ca93",
      "metadata": {
        "id": "1bfa7c67-b96a-41e0-89b6-1ea801c9ca93"
      },
      "source": [
        "# TASK 8. BUILDING & TESTING THE RAG CHAIN USING LANGCHAIN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5474bc0a-abec-43f4-b6d5-a3a9090058b5",
      "metadata": {
        "id": "5474bc0a-abec-43f4-b6d5-a3a9090058b5"
      },
      "source": [
        "\n",
        "Now we assemble the core RAG logic using Langchain's `RetrievalQAWithSourcesChain`. This chain combines:\n",
        "1.  A **Retriever**: Fetches relevant documents from our `vector_store`.\n",
        "2.  An **LLM**: Generates the answer based on the question and retrieved documents (we'll use OpenAI).\n",
        "\n",
        "This specific chain type automatically handles retrieving documents, formatting them with the question for the LLM, and tracking the sources.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54460ccd-d638-42f9-b172-a127770cace9",
      "metadata": {
        "id": "54460ccd-d638-42f9-b172-a127770cace9",
        "outputId": "cc6b9961-e82a-4d27-84a8-b721aa5ccd20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retriever configured successfully from vector store.\n",
            "OpenAI LLM successfully initialized.\n",
            "RetrievalQAWithSourcesChain created\n"
          ]
        }
      ],
      "source": [
        "# --- 1. Define the Retriever ---\n",
        "# The retriever uses the vector store to fetch documents\n",
        "# We configure it to retrieve the top 'k' documents\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "print(\"Retriever configured successfully from vector store.\")\n",
        "\n",
        "# --- 2. Define the Language Model (LLM) from OpenAI---\n",
        "# Temperature controls the model's creativity; 'temperature=0' aims for more factual, less creative answers\n",
        "# You might need to specify a more powerful model, such as \"gpt-3.5-turbo-instruct\"\n",
        "llm = OpenAI(temperature = 1.3, openai_api_key = openai_api_key)\n",
        "print(\"OpenAI LLM successfully initialized.\")\n",
        "\n",
        "# --- 3. Create the RetrievalQAWithSourcesChain ---\n",
        "# This chain type is designed specifically for Q&A with source tracking.\n",
        "# chain_type=\"stuff\": Puts all retrieved text directly into the prompt context.\n",
        "#                      Suitable if the total text fits within the LLM's context limit.\n",
        "#                      Other types like \"map_reduce\" handle larger amounts of text.\n",
        "qa_chain = RetrievalQAWithSourcesChain.from_chain_type(llm = llm,\n",
        "                                                       chain_type = \"stuff\",\n",
        "                                                       retriever = retriever,\n",
        "                                                       return_source_documents = True,  # Request the actual Document objects used\n",
        "                                                       verbose = True)  # Set to True to see Langchain's internal steps (can be noisy)\n",
        "\n",
        "print(\"RetrievalQAWithSourcesChain created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9203b190-cc40-4f39-87c8-4a8af34e618a",
      "metadata": {
        "id": "9203b190-cc40-4f39-87c8-4a8af34e618a",
        "outputId": "d583a410-90c4-408d-9055-db4f0ca89312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Testing the Full RAG Chain ---\n",
            "Query: What kind of food does Eleven Madison Park serve?\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQAWithSourcesChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "--- Answer ---\n",
            " Eleven Madison Park serves a discounted plant-based menu and farm-sourced à la carte snacks, reservations are required.\n",
            "\n",
            "\n",
            "--- Sources ---\n",
            "https://www.elevenmadisonpark.com/faq\n",
            "\n",
            "--- Source Document Snippets ---\n",
            "Doc 1: Welcome to Eleven Madison Park Eleven Madison Park is a fine dining restaurant in the heart of New York City. Overlooking Madison Square Park–one of Manhattan’s most beautiful green spaces–we sit at the base of a historic Art Deco building on the cor\n",
            "Doc 2: Source: https://www.elevenmadisonpark.com/ourrestaurant\n",
            "Title: About — Eleven Madison Park\n",
            "Content:\n",
            "Doc 3: Source: https://www.elevenmadisonpark.com/faq\n",
            "Title: FAQs — Eleven Madison Park\n",
            "Content:\n"
          ]
        }
      ],
      "source": [
        "# --- Test the Full Chain ---\n",
        "print(\"\\n--- Testing the Full RAG Chain ---\")\n",
        "chain_test_query = \"What kind of food does Eleven Madison Park serve?\"\n",
        "print(f\"Query: {chain_test_query}\")\n",
        "\n",
        "# Run the query through the chain. Use invoke() for Langchain >= 0.1.0\n",
        "# The input must be a dictionary, often with the key 'question'.\n",
        "try:\n",
        "    result = qa_chain.invoke({\"question\": chain_test_query})\n",
        "\n",
        "    # Print the answer and sources from the result dictionary\n",
        "    print(\"\\n--- Answer ---\")\n",
        "    print(result.get(\"answer\", \"No answer generated.\"))\n",
        "\n",
        "    print(\"\\n--- Sources ---\")\n",
        "    print(result.get(\"sources\", \"No sources identified.\"))\n",
        "\n",
        "    # Optionally print snippets from the source documents returned\n",
        "    if \"source_documents\" in result:\n",
        "        print(\"\\n--- Source Document Snippets ---\")\n",
        "        for i, doc in enumerate(result[\"source_documents\"]):\n",
        "            content_snippet = doc.page_content[:250].strip()\n",
        "            print(f\"Doc {i+1}: {content_snippet}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred while running the chain: {e}\")\n",
        "    # Consider adding more specific error handling if needed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c26fdd4-225e-41f0-bb4e-e21d5f2e030b",
      "metadata": {
        "id": "4c26fdd4-225e-41f0-bb4e-e21d5f2e030b"
      },
      "source": [
        "**PRACTICE OPPORTUNITY:**\n",
        "- **Look at the `result` dictionary printed by the chain test. What are the key pieces of information it contains?**\n",
        "- **Change `temperature=0` to `temperature=1.3` in the `llm = OpenAI(...)` line. Re-run the cell and ask the *same* `chain_test_query`. Does the wording of the answer change slightly? Change it back to `0`.**\n",
        "- **Set `verbose=True` and `return_source_documents=True` in the `RetrievalQAWithSourcesChain.from_chain_type(...)` line. Re-run the cell. What extra information do you see printed? Set it back to `False`.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "323612ee-5335-4933-8044-36cb916fb369",
      "metadata": {
        "id": "323612ee-5335-4933-8044-36cb916fb369"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "87c86df0-ce5d-4596-92e9-02e7db65c164",
      "metadata": {
        "id": "87c86df0-ce5d-4596-92e9-02e7db65c164"
      },
      "source": [
        "# TASK 9. CREATING A GRADIO INTERFACE FOR OUR RAG CHAIN"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10febf62-82fb-483d-9d9f-82610eb842b8",
      "metadata": {
        "id": "10febf62-82fb-483d-9d9f-82610eb842b8"
      },
      "source": [
        "Let's wrap our RAG chain in a user-friendly web interface using Gradio. Users will type a question, click a button, and see the answer along with the sources the AI used.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35fdc62b-8bae-4a0d-b049-786ae6a2b930",
      "metadata": {
        "id": "35fdc62b-8bae-4a0d-b049-786ae6a2b930"
      },
      "outputs": [],
      "source": [
        "# Gradio for UI\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7459c671-7aad-4672-97c4-fd531604f86e",
      "metadata": {
        "id": "7459c671-7aad-4672-97c4-fd531604f86e",
        "outputId": "a14c0a2c-ac83-4290-d74c-37471b19ebe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Setting up Gradio interface...\n",
            "Gradio interface defined.\n",
            "\n",
            "Launching Gradio app... (Stop the kernel or press Ctrl+C in terminal to quit)\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --- Define the Function for Gradio ---\n",
        "\n",
        "# This function takes the user's input, runs the chain, and formats the output\n",
        "# Ensure the `qa_chain` variable is accessible in this scope.\n",
        "def ask_elevenmadison_assistant(user_query):\n",
        "    \"\"\"\n",
        "    Processes the user query using the RAG chain and returns formatted results.\n",
        "    \"\"\"\n",
        "    print(f\"\\nProcessing Gradio query: '{user_query}'\")\n",
        "    if not user_query or user_query.strip() == \"\":\n",
        "        print(\"--> Empty query received.\")\n",
        "        return \"Please enter a question.\", \"\"  # Handle empty input gracefully\n",
        "\n",
        "    try:\n",
        "        # Run the query through our RAG chain\n",
        "        result = qa_chain.invoke({\"question\": user_query})\n",
        "\n",
        "        # Extract answer and sources\n",
        "        answer = result.get(\"answer\", \"Sorry, I couldn't find an answer in the provided documents.\")\n",
        "        sources = result.get(\"sources\", \"No specific sources identified.\")\n",
        "\n",
        "        # Basic formatting for sources (especially if it just returns the filename)\n",
        "        if sources == DATA_FILE_PATH:\n",
        "            sources = f\"Retrieved from: {DATA_FILE_PATH}\"\n",
        "        elif isinstance(sources, list):  # Handle potential list of sources\n",
        "            sources = \", \".join(list(set(sources)))  # Unique, comma-separated\n",
        "\n",
        "        print(f\"--> Answer generated: {answer[:100].strip()}...\")\n",
        "        print(f\"--> Sources identified: {sources}\")\n",
        "\n",
        "        # Return the answer and sources to be displayed in Gradio output components\n",
        "        return answer.strip(), sources\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"An error occurred: {e}\"\n",
        "        print(f\"--> Error during chain execution: {error_message}\")\n",
        "        # Return error message to the user interface\n",
        "        return error_message, \"Error occurred\"\n",
        "\n",
        "\n",
        "# --- Create the Gradio Interface using Blocks API ---\n",
        "print(\"\\nSetting up Gradio interface...\")\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"Eleven Madison Park Q&A Assistant\") as demo:\n",
        "    # Title and description for the app\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # Eleven Madison Park - AI Q&A Assistant 💬\n",
        "        Ask questions about the restaurant based on its website data.\n",
        "        The AI provides answers and cites the source document.\n",
        "        *(Examples: What are the menu prices? Who is the chef? Is it plant-based?)*\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Input component for the user's question\n",
        "    question_input = gr.Textbox(\n",
        "        label = \"Your Question:\",\n",
        "        placeholder = \"e.g., What are the opening hours on Saturday?\",\n",
        "        lines = 2,  # Allow a bit more space for longer questions\n",
        "    )\n",
        "\n",
        "    # Row layout for the output components\n",
        "    with gr.Row():\n",
        "        # Output component for the generated answer (read-only)\n",
        "        answer_output = gr.Textbox(label=\"Answer:\", interactive=False, lines=6)  # User cannot edit this\n",
        "        # Output component for the sources (read-only)\n",
        "        sources_output = gr.Textbox(label=\"Sources:\", interactive=False, lines=2)\n",
        "\n",
        "    # Row for buttons\n",
        "    with gr.Row():\n",
        "        # Button to submit the question\n",
        "        submit_button = gr.Button(\"Ask Question\", variant=\"primary\")\n",
        "        # Clear button to reset inputs and outputs\n",
        "        clear_button = gr.ClearButton(components=[question_input, answer_output, sources_output], value=\"Clear All\")\n",
        "\n",
        "    # Add some example questions for users to try\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            \"What are the different menu options and prices?\",\n",
        "            \"Who is the head chef?\",\n",
        "            \"What is Magic Farms?\"],\n",
        "        inputs=question_input,  # Clicking example loads it into this input\n",
        "        # We could potentially add outputs=[answer_output, sources_output] and cache examples\n",
        "        # but that requires running the chain for each example beforehand.\n",
        "        cache_examples=False,  # Don't pre-compute results for examples for simplicity\n",
        "    )\n",
        "\n",
        "    # --- Connect the Submit Button to the Function ---\n",
        "    # When submit_button is clicked, call 'ask_emp_assistant'\n",
        "    # Pass the value from 'question_input' as input\n",
        "    # Put the returned values into 'answer_output' and 'sources_output' respectively\n",
        "    submit_button.click(fn = ask_elevenmadison_assistant, inputs = question_input, outputs = [answer_output, sources_output])\n",
        "\n",
        "print(\"Gradio interface defined.\")\n",
        "\n",
        "# --- Launch the Gradio App ---\n",
        "print(\"\\nLaunching Gradio app... (Stop the kernel or press Ctrl+C in terminal to quit)\")\n",
        "# demo.launch() # Launch locally in the notebook or browser\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f5ffe76-ca3d-45e9-af70-564f20eb6d7f",
      "metadata": {
        "id": "7f5ffe76-ca3d-45e9-af70-564f20eb6d7f"
      },
      "source": [
        "**PRACTICE OPPORTUNITY:**\n",
        "- **Expand on the example questions to include the ones below. Rerun the app and test them out.**\n",
        "    - **\"Do I need a reservation for the bar?\"**\n",
        "    - **\"What is the dress code?**\n",
        "    - **\"Can I buy gift cards?\"**\n",
        "- **Change the text on the submit button from `Ask Question` to `Ask Eleven Madison Park AI 🤖`. Where do you make this change?**\n",
        "- **We already added a `gr.ClearButton` in the code above. Test it out! Ask a question, get an answer, then click the \"Clear All\" button. Does it clear the question, answer, and sources fields?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a75b7d2f-d6bc-44aa-9a1b-326f173710a6",
      "metadata": {
        "id": "a75b7d2f-d6bc-44aa-9a1b-326f173710a6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeaea1f1-c641-4de9-a4c9-30dc6f8be250",
      "metadata": {
        "id": "aeaea1f1-c641-4de9-a4c9-30dc6f8be250"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "373bc161-c6c3-4380-b93f-8063488a4b7e",
      "metadata": {
        "id": "373bc161-c6c3-4380-b93f-8063488a4b7e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1fb2d82-c6d2-4f8b-beae-95d92415b030",
      "metadata": {
        "id": "e1fb2d82-c6d2-4f8b-beae-95d92415b030"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c7f7f376-b776-428b-8266-0861ea8e4229",
      "metadata": {
        "id": "c7f7f376-b776-428b-8266-0861ea8e4229"
      },
      "source": [
        "# PRACTICE OPPORTUNITY SOLUTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "215d8ab5-f965-4160-9781-3ff5dbc71a5d",
      "metadata": {
        "id": "215d8ab5-f965-4160-9781-3ff5dbc71a5d"
      },
      "source": [
        "**PRACTICE OPPORTUNITY SOLUTION:**\n",
        "- **Display the last 750 characters in the loaded document**\n",
        "- **Perform a sanity check by comparing the printed characters to `eleven_madison_park_data.txt` file**\n",
        "- **Print the email and the phone number of the restaurant**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "190b7d15-c582-419a-9174-e7e4095d1144",
      "metadata": {
        "id": "190b7d15-c582-419a-9174-e7e4095d1144"
      },
      "outputs": [],
      "source": [
        "# Let's display the last characters of the loaded content\n",
        "print(raw_documents[0].page_content[-750:] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fb4c252-7b7c-40a5-b9c2-a2ef3c45f17d",
      "metadata": {
        "id": "5fb4c252-7b7c-40a5-b9c2-a2ef3c45f17d"
      },
      "source": [
        "**PRACTICE OPPORTUNITY SOLUTION:**\n",
        "- **Change `chunk_size` to `500` in the `RecursiveCharacterTextSplitter` and re-run the cell. How many chunks do you get now? Is it more or less than before? Change it back to `1000`**\n",
        "- **Change `chunk_overlap` to `0` and re-run the cell. Does the number of chunks change drastically? What problem might setting overlap to 0 cause? Change it back to `150`**\n",
        "- **Print the last example chunk and its metadata and re-run the cell. What information is stored in the `metadata`? Why is the `'source'` important?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68b522c7-75ff-4116-a8e2-29fb855dda3d",
      "metadata": {
        "id": "68b522c7-75ff-4116-a8e2-29fb855dda3d"
      },
      "outputs": [],
      "source": [
        "# Let's display an example chunk and its metadata\n",
        "print(\"\\n--- Example Chunk (Last Chunk) ---\")\n",
        "print(documents[-1].page_content)\n",
        "print(\"\\n--- Metadata for Last Chunk---\")\n",
        "print(documents[-1].metadata)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d35bfcfd-391d-4ee9-aa65-541ef0b13cfa",
      "metadata": {
        "id": "d35bfcfd-391d-4ee9-aa65-541ef0b13cfa"
      },
      "source": [
        "1. Changing `chunk_size=500` will result in *more* chunks being created because the original document is being divided into smaller pieces. The exact number depends on the total text length and overlap.\n",
        "2. Changing `chunk_overlap=0` might slightly change the total number of chunks, but usually not by a large amount compared to changing the chunk size. The potential problem with zero overlap is that if an important sentence or idea happens to fall exactly on the boundary between two chunks, it might get cut in half, and the full context could be lost in both resulting chunks. Overlap mitigates this by ensuring some context is repeated.\n",
        "3. The `'source'` key is crucial because it links the chunk back to its origin file, allowing the RAG chain to later report this source when providing citations for its answer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ddea60c-2ec7-4fea-ae44-b2223bc7932d",
      "metadata": {
        "id": "6ddea60c-2ec7-4fea-ae44-b2223bc7932d"
      },
      "source": [
        "**PRACTICE OPPORTUNITY SOLUTION:**\n",
        "- **Using Tensorflow Embeddings Projector, explore the nearest points to \"Italy\"**\n",
        "- **Choose 2 additional different words that you like**\n",
        "- **Tensorflow Ebeddings projector: https://projector.tensorflow.org/**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af9fe721-3c82-4eb2-92b8-af4c5e36a288",
      "metadata": {
        "id": "af9fe721-3c82-4eb2-92b8-af4c5e36a288"
      },
      "source": [
        "![image.png](attachment:e8df0fdd-95e7-4f23-9b6a-f9c93d3cbed5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f68d5b0c-1d84-415d-a98c-87af8043427e",
      "metadata": {
        "id": "f68d5b0c-1d84-415d-a98c-87af8043427e"
      },
      "source": [
        "**PRACTICE OPPORTUNITY SOLUTION:**\n",
        "- **Change the `test_query` variable to ask one of the following questions. Re-run the cell for each question. Do the retrieved document snippets seem relevant to your question?**\n",
        "    - `\"Who is Daniel Humm?\"`\n",
        "    - `\"Is there a dress code?\"`\n",
        "    - `\"Tell me about the partnership with Magic Farms.\"`\n",
        "    - `\"How do I make a reservation?\"`\n",
        "- **Adjust the value of k to `k=1` and then to `k=5`. Re-run the cell. How does changing `k` affect the number of documents retrieved?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39c08a5f-d730-4078-b086-01c0b70431af",
      "metadata": {
        "id": "39c08a5f-d730-4078-b086-01c0b70431af"
      },
      "outputs": [],
      "source": [
        "# Let's perform a similarity search in our vector store\n",
        "print(\"\\n--- Testing Similarity Search in Vector Store ---\")\n",
        "test_query = \"Tell me about the partnership with Magic Farms.\"\n",
        "print(f\"Searching for documents similar to: '{test_query}'\")\n",
        "\n",
        "\n",
        "# Perform a similarity search. 'k=2' retrieves the top 3 most similar chunks\n",
        "try:\n",
        "    similar_docs = vector_store.similarity_search(test_query, k = 1)\n",
        "    print(f\"\\nFound {len(similar_docs)} similar documents:\")\n",
        "\n",
        "    # Display snippets of the retrieved documents and their sources\n",
        "    for i, doc in enumerate(similar_docs):\n",
        "        print(f\"\\n--- Document {i+1} ---\")\n",
        "        # Displaying the first 700 chars for brevity\n",
        "        content_snippet = doc.page_content[:700].strip() + \"...\"\n",
        "        source = doc.metadata.get(\"source\", \"Unknown Source\")  # Get source from metadata\n",
        "        print(f\"Content Snippet: {content_snippet}\")\n",
        "        print(f\"Source: {source}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during similarity search: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf874afa-761b-4889-a929-d53bad572774",
      "metadata": {
        "id": "cf874afa-761b-4889-a929-d53bad572774"
      },
      "source": [
        "**PRACTICE OPPORTUNITY SOLUTION:**\n",
        "- **Look at the `result` dictionary printed by the chain test. What are the key pieces of information it contains?**\n",
        "- **Change `temperature=0` to `temperature=1.3` in the `llm = OpenAI(...)` line. Re-run the cell and ask the *same* `chain_test_query`. Does the wording of the answer change slightly? Change it back to `0`.**\n",
        "- **Set `verbose=True` and `return_source_documents=True` in the `RetrievalQAWithSourcesChain.from_chain_type(...)` line. Re-run the cell. What extra information do you see printed? Set it back to `False`.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e2d8d58-c415-4dd7-b6f5-cd89d5e29cdd",
      "metadata": {
        "id": "4e2d8d58-c415-4dd7-b6f5-cd89d5e29cdd",
        "outputId": "643dbfb2-3614-47ca-c65e-c73b05194b95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What kind of food does Eleven Madison Park serve?',\n",
              " 'answer': ' Eleven Madison Park serves a discounted plant-based menu and farm-sourced à la carte snacks, reservations are required.\\n',\n",
              " 'sources': 'https://www.elevenmadisonpark.com/faq',\n",
              " 'source_documents': [Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Welcome to Eleven Madison Park Eleven Madison Park is a fine dining restaurant in the heart of New York City. Overlooking Madison Square Park–one of Manhattan’s most beautiful green spaces–we sit at the base of a historic Art Deco building on the corner of East 24th Street and Madison Avenue. Since opening in 1998, we underwent a full-scale renovation and redesign in the summer of 2017. Chef Daniel Humm has owned the restaurant since 2011, during which time we have evolved considerably in both cuisine and experience. In 2021, we transitioned to a fully plant-based menu, using no animal products. That same year, we partnered with Magic Farms , which grows produce exclusively for our seasonal menus. Guests can enjoy a full tasting menu, a five-course menu, or a bar menu. The bar also offers à la carte snacks, as well as wine and cocktails. Reservations are available via Resy , and bar seating is open for both walk-ins and reservations. Hours: Monday to Wednesday: 5:30 pm to 10 pm'),\n",
              "  Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Source: https://www.elevenmadisonpark.com/ourrestaurant\\nTitle: About — Eleven Madison Park\\nContent:'),\n",
              "  Document(metadata={'source': 'eleven_madison_park_data.txt'}, page_content='Source: https://www.elevenmadisonpark.com/faq\\nTitle: FAQs — Eleven Madison Park\\nContent:')]}"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5c057a0-e82c-4177-91c4-78e37910845a",
      "metadata": {
        "id": "a5c057a0-e82c-4177-91c4-78e37910845a"
      },
      "source": [
        "1.  **Chain Output:** The `result` dictionary from `RetrievalQAWithSourcesChain` typically contains:\n",
        "    *   `'question'`: The original input question.\n",
        "    *   `'answer'`: The textual answer generated by the LLM based on the retrieved context.\n",
        "    *   `'sources'`: A string listing the source(s) identified (often the filename from the metadata of the used documents).\n",
        "    *   `'source_documents'`: If `return_source_documents=True`, this key holds a list of the actual Langchain `Document` objects that were retrieved and passed to the LLM.\n",
        "2.  **Temperature Effect:** Changing `temperature=1.3` introduces more randomness into the LLM's generation process. While the answer should still be based on the retrieved context, the exact phrasing, sentence structure, or choice of words might vary slightly each time you run the query, compared to the more deterministic output with `temperature=0`.\n",
        "3.  **Verbose Mode:** Setting `verbose=True` causes Langchain to print detailed internal logs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7e714ae-6459-47f4-af93-ae5b8253619e",
      "metadata": {
        "id": "d7e714ae-6459-47f4-af93-ae5b8253619e"
      },
      "source": [
        "**PRACTICE OPPORTUNITY SOLUTION:**\n",
        "- **Expand on the example questions to include the ones below. Rerun the app and test them out.**\n",
        "    - **\"Do I need a reservation for the bar?\"**\n",
        "    - **\"What is the dress code?**\n",
        "    - **\"Can I buy gift cards?\"**\n",
        "- **Change the text on the submit button from `Ask Question` to `Ask Eleven Madison Park AI 🤖`. Where do you make this change?**\n",
        "- **We already added a `gr.ClearButton` in the code above. Test it out! Ask a question, get an answer, then click the \"Clear All\" button. Does it clear the question, answer, and sources fields?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ebdee8b-beb6-4f06-9aee-b25dcfd5cb45",
      "metadata": {
        "id": "9ebdee8b-beb6-4f06-9aee-b25dcfd5cb45",
        "outputId": "daa675db-941a-47c5-aa15-ce7dd56c415d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Setting up Gradio interface...\n",
            "Gradio interface defined.\n",
            "\n",
            "Launching Gradio app... (Stop the kernel or press Ctrl+C in terminal to quit)\n",
            "* Running on local URL:  http://127.0.0.1:7861\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --- Define the Function for Gradio ---\n",
        "\n",
        "# This function takes the user's input, runs the chain, and formats the output\n",
        "# Ensure the `qa_chain` variable is accessible in this scope.\n",
        "def ask_elevenmadison_assistant(user_query):\n",
        "    \"\"\"\n",
        "    Processes the user query using the RAG chain and returns formatted results.\n",
        "    \"\"\"\n",
        "    print(f\"\\nProcessing Gradio query: '{user_query}'\")\n",
        "    if not user_query or user_query.strip() == \"\":\n",
        "        print(\"--> Empty query received.\")\n",
        "        return \"Please enter a question.\", \"\"  # Handle empty input gracefully\n",
        "\n",
        "    try:\n",
        "        # Run the query through our RAG chain\n",
        "        result = qa_chain.invoke({\"question\": user_query})\n",
        "\n",
        "        # Extract answer and sources\n",
        "        answer = result.get(\"answer\", \"Sorry, I couldn't find an answer in the provided documents.\")\n",
        "        sources = result.get(\"sources\", \"No specific sources identified.\")\n",
        "\n",
        "        # Basic formatting for sources (especially if it just returns the filename)\n",
        "        if sources == DATA_FILE_PATH:\n",
        "            sources = f\"Retrieved from: {DATA_FILE_PATH}\"\n",
        "        elif isinstance(sources, list):  # Handle potential list of sources\n",
        "            sources = \", \".join(list(set(sources)))  # Unique, comma-separated\n",
        "\n",
        "        print(f\"--> Answer generated: {answer[:100].strip()}...\")\n",
        "        print(f\"--> Sources identified: {sources}\")\n",
        "\n",
        "        # Return the answer and sources to be displayed in Gradio output components\n",
        "        return answer.strip(), sources\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"An error occurred: {e}\"\n",
        "        print(f\"--> Error during chain execution: {error_message}\")\n",
        "        # Return error message to the user interface\n",
        "        return error_message, \"Error occurred\"\n",
        "\n",
        "\n",
        "# --- Create the Gradio Interface using Blocks API ---\n",
        "print(\"\\nSetting up Gradio interface...\")\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"EMP Q&A Assistant\") as demo:\n",
        "    # Title and description for the app\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # Eleven Madison Park - AI Q&A Assistant 💬\n",
        "        Ask questions about the restaurant based on its website data.\n",
        "        The AI provides answers and cites the source document.\n",
        "        *(Examples: What are the menu prices? Who is the chef? Is it plant-based?)*\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Input component for the user's question\n",
        "    question_input = gr.Textbox(\n",
        "        label = \"Your Question:\",\n",
        "        placeholder = \"e.g., What are the opening hours on Saturday?\",\n",
        "        lines = 2,  # Allow a bit more space for longer questions\n",
        "    )\n",
        "\n",
        "    # Row layout for the output components\n",
        "    with gr.Row():\n",
        "        # Output component for the generated answer (read-only)\n",
        "        answer_output = gr.Textbox(label=\"Answer:\", interactive=False, lines=6)  # User cannot edit this\n",
        "        # Output component for the sources (read-only)\n",
        "        sources_output = gr.Textbox(label=\"Sources:\", interactive=False, lines=2)\n",
        "\n",
        "    # Row for buttons\n",
        "    with gr.Row():\n",
        "        # Button to submit the question\n",
        "        submit_button = gr.Button(\"Ask Eleven Madison Park AI 🤖\", variant=\"primary\")\n",
        "        # Clear button to reset inputs and outputs\n",
        "        clear_button = gr.ClearButton(components=[question_input, answer_output, sources_output], value=\"Clear All\")\n",
        "\n",
        "    # Add some example questions for users to try\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            \"What are the different menu options and prices?\",\n",
        "            \"Who is the head chef?\",\n",
        "            \"What is Magic Farms?\",\n",
        "            \"Do I need a reservation for the bar?\",\n",
        "            \"What is the dress code?\",\n",
        "            \"Can I buy gift cards?\"],\n",
        "        inputs=question_input,  # Clicking example loads it into this input\n",
        "        # We could potentially add outputs=[answer_output, sources_output] and cache examples\n",
        "        # but that requires running the chain for each example beforehand.\n",
        "        cache_examples=False,  # Don't pre-compute results for examples for simplicity\n",
        "    )\n",
        "\n",
        "    # --- Connect the Submit Button to the Function ---\n",
        "    # When submit_button is clicked, call 'ask_emp_assistant'\n",
        "    # Pass the value from 'question_input' as input\n",
        "    # Put the returned values into 'answer_output' and 'sources_output' respectively\n",
        "    submit_button.click(fn = ask_elevenmadison_assistant, inputs = question_input, outputs = [answer_output, sources_output])\n",
        "\n",
        "print(\"Gradio interface defined.\")\n",
        "\n",
        "# --- Launch the Gradio App ---\n",
        "print(\"\\nLaunching Gradio app... (Stop the kernel or press Ctrl+C in terminal to quit)\")\n",
        "# demo.launch() # Launch locally in the notebook or browser\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8dc498d-b3cd-453d-8171-fe5a94820195",
      "metadata": {
        "id": "d8dc498d-b3cd-453d-8171-fe5a94820195"
      },
      "source": [
        "![image.png](attachment:8487929a-c0b8-4f1c-88be-c422bcca486b.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd65b9ea-cf3a-4ff4-86a8-d9b955cb42cd",
      "metadata": {
        "id": "cd65b9ea-cf3a-4ff4-86a8-d9b955cb42cd"
      },
      "source": [
        "![image.png](attachment:599c4221-1f20-4ddc-b18e-fcc855aa2fc9.png)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}